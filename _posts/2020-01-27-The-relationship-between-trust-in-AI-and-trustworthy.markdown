---
layout: page
title:  "The relationship between trust in AI and trustworthy machine learning technologies"
date:   2020-01-27 15:15:49 +0000
author: Ehsan Toreini
categories: trust
---
**Authors:** *Ehsan Toreini; Mhairi Aitken; Kovila Coopamootoo; Karen Elliott; Carlos Gonzalez Zelayaï¼›Aad van Moorsel*

To design and develop AI-based systems that users and the larger public can justifiably trust, one needs to understand how machine learning technologies impact trust. To guide the design and implementation of trusted AI-based systems, this paper provides a systematic approach to relate considerations about trust from the social sciences to trustworthiness technologies proposed for AI-based services and products. We start from the ABI+ (Ability, Benevolence, Integrity, Predictability) framework augmented with a recently proposed mapping of ABI+ on qualities of technologies that support trust. We consider four categories of trustworthiness technologies for machine learning, namely these for Fairness, Explainability, Auditability and Safety (FEAS) and discuss if and how these support the required qualities. Moreover, trust can be impacted throughout the life cycle of AI-based systems, and we therefore introduce the concept of Chain of Trust to discuss trustworthiness technologies in all stages of the life cycle. In so doing we establish the ways in which machine learning technologies support trusted AI-based systems. Finally, FEAS has obvious relations with known frameworks and therefore we relate FEAS to a variety of international 'principled AI' policy and technology frameworks that have emerged in recent years.

*Full-text available [here](https://dl.acm.org/doi/pdf/10.1145/3351095.3372834?casa_token=7BDYoLbqTFoAAAAA:dSAUxS_qWPhmb_gtOHlj7_AIQky_8U7B7fZZYU1PkB2nI5AzPsxFyy26McKo_ax64awgQCOnVPVHuDo)*